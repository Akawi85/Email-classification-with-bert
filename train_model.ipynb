{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1655587329241,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"70QsAxYGjEor","outputId":"ca994d2c-3f26-4501-e899-fd84d6e2f5d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Code_challenge\n"]}],"source":["%cd /content/drive/MyDrive/Code_challenge"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12002,"status":"ok","timestamp":1655587341587,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"QFZAWeQzlYDG","outputId":"bc712004-7b6e-4e1b-e65e-3673451dfc70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362 kB 24.1 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212 kB 68.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140 kB 57.5 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 61.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 73.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127 kB 75.9 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 66.5 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94 kB 3.5 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271 kB 66.6 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.7.0 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["# install hugging face datasets module\n","!pip install datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9072,"status":"ok","timestamp":1655587409671,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"O8Egk4utk--s","outputId":"ec7d8f19-f814-4134-d3dc-f18e099da748"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.4 MB 30.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.6 MB 43.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.12.1 transformers-4.20.0\n"]}],"source":["# install transformers library\n","!pip install transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9023,"status":"ok","timestamp":1655587426734,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"KiLRpLEfmxqM"},"outputs":[],"source":["# import necessary packages\n","import transformers, pandas as pd\n","from datasets import Dataset, load_metric\n","import numpy as np\n","from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, AutoModelForSequenceClassification, Trainer"]},{"cell_type":"markdown","metadata":{"id":"ZaF59TvWsQI8"},"source":["### Prepare the Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1655587435898,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"BH2OXp2YjT7F"},"outputs":[],"source":["# create the sample emails texts\n","sample_mails = [\"I will share your email\",\n","\"I shall share your email\",\n","\"I've shared your email\",\n","\"May I share your email\",\n","\"Should I share your email\",\n","\"I already shared the email\",\n","\"I've just shared your email\",\n","\"Am I allowed to share your email\",\n","\"Am I able to share your email\",\n","\"I am able to share your email\",\n","\"Will you help my friends if I share your email with them?\"]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":330,"status":"ok","timestamp":1655587437694,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"D_c1iidVjoSS"},"outputs":[],"source":["# manually create a label match for each sample mail\n","mail_labels = [\"Student wants to know if can share\",\n","\"Student wants to know if can share\",\n","\"Student has shared\",\n","\"Student wants to know if can share\",\n","\"Student wants to know if can share\",\n","\"Student has shared\",\n","\"Student has shared\",\n","\"Student wants to know if can share\",\n","\"Student wants to know if can share\",\n","\"Student has shared\",\n","\"Student wants to know if can share\"]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1655587468013,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"nuQB_BJhoLRl","outputId":"e3890f25-acb9-42e7-a0f1-2192b1739298"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a21453a1-7292-418b-8726-02dc84d2596b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sample_mails</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I will share your email</td>\n","      <td>Student wants to know if can share</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I shall share your email</td>\n","      <td>Student wants to know if can share</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I've shared your email</td>\n","      <td>Student has shared</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>May I share your email</td>\n","      <td>Student wants to know if can share</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Should I share your email</td>\n","      <td>Student wants to know if can share</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>I already shared the email</td>\n","      <td>Student has shared</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>I've just shared your email</td>\n","      <td>Student has shared</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Am I allowed to share your email</td>\n","      <td>Student wants to know if can share</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Am I able to share your email</td>\n","      <td>Student wants to know if can share</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>I am able to share your email</td>\n","      <td>Student has shared</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Will you help my friends if I share your email...</td>\n","      <td>Student wants to know if can share</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a21453a1-7292-418b-8726-02dc84d2596b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a21453a1-7292-418b-8726-02dc84d2596b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a21453a1-7292-418b-8726-02dc84d2596b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                         sample_mails  \\\n","0                             I will share your email   \n","1                            I shall share your email   \n","2                              I've shared your email   \n","3                              May I share your email   \n","4                           Should I share your email   \n","5                          I already shared the email   \n","6                         I've just shared your email   \n","7                    Am I allowed to share your email   \n","8                       Am I able to share your email   \n","9                       I am able to share your email   \n","10  Will you help my friends if I share your email...   \n","\n","                                labels  \n","0   Student wants to know if can share  \n","1   Student wants to know if can share  \n","2                   Student has shared  \n","3   Student wants to know if can share  \n","4   Student wants to know if can share  \n","5                   Student has shared  \n","6                   Student has shared  \n","7   Student wants to know if can share  \n","8   Student wants to know if can share  \n","9                   Student has shared  \n","10  Student wants to know if can share  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# load dataset as pandas Dataframe\n","df = pd.DataFrame({'sample_mails': sample_mails, 'labels': mail_labels})\n","\n","# check\n","df"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1655587493109,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"19mTVz2rrrqP","outputId":"f447a33a-c8e4-455e-d645-d1f9c36e0d2d"},"outputs":[{"data":{"text/plain":["datasets.arrow_dataset.Dataset"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# load the dataframe in a hugging face compatible format\n","dataset = Dataset.from_pandas(df)\n","\n","# check the type\n","type(dataset)"]},{"cell_type":"markdown","metadata":{"id":"AbFltOF2uvIk"},"source":["### Preprocessing the dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["0d8302ca67134193a10ade69c44041bf","89e96f9fcfed418895ef4887072b134d","c6b02c2d616f41af9ded54c7916709ee","b88ce659f6f4451eb43bf7bd6610f0d6","30b853bfac2d4eafafa5208e914aa40e","5fe39bf5c8d446dc8dc9aa86429b7423","bf060a5ee51b458aa6517a3bf503e59b","a2505a274ff243589f05bf088c1e0992","36c4eb53fb1f40f9bd232c59979d52db","f9214a7b86334b92b3df3f3389cf154e","7202ebce10d943f5885631fc36418058","f954762c305c4be9ae3fd2682e7efe53","459c48905efe477cb25c5eb8dc3c0571","27549b8720c741199e42b55049ac1c1f","10ef2c11a1754e708834372100e6eb5b","b7032e7ea083403d9abf038b48c328e5","fe8e0db9a7ce4810974b58c0f7fb9ff4","840f26b2aa4640b4919625d9504df3f6","823582762af34fa3b85ab758fc06d8a3","df7418fee5f34b0584500f63aaa480eb","c1cf39a62d064404920f5dbc2175829e","d1d37f46d21e476b80319fb3143055ff"]},"executionInfo":{"elapsed":72,"status":"ok","timestamp":1655570875322,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"dNNz2rv70Yfj","outputId":"339a52c1-ebd4-4a4c-82f6-c101a7213eb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Parameter 'function'=<function Dataset.class_encode_column.<locals>.cast_to_class_labels at 0x7fe90e07a050> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d8302ca67134193a10ade69c44041bf","version_major":2,"version_minor":0},"text/plain":["Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f954762c305c4be9ae3fd2682e7efe53","version_major":2,"version_minor":0},"text/plain":["Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# encode the dataset labels as integers\n","dataset = dataset.class_encode_column('labels')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1655570875323,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"cH03nZ8OqJOx","outputId":"182d1a02-e701-4e42-bb32-5d19048df666"},"outputs":[{"data":{"text/plain":["{'labels': 0, 'sample_mails': \"I've shared your email\"}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# view a sample of the dataset\n","dataset[2]"]},{"cell_type":"markdown","metadata":{"id":"XH34IgbA-sd3"},"source":["From the above output, we see that label `0` indicates the label `Student has shared` therefore label `1` will indicate `Student wants to know if can share`"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1655570875324,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"_0RBElLCxqnZ","outputId":"4ec48573-84b6-46fa-bbee-bb737aaa8b81"},"outputs":[{"data":{"text/plain":["{'labels': ClassLabel(num_classes=2, names=['Student has shared', 'Student wants to know if can share'], id=None),\n"," 'sample_mails': Value(dtype='string', id=None)}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# verify the dataset features\n","dataset.features"]},{"cell_type":"markdown","metadata":{"id":"nRpuYrIwNF6-"},"source":["### Tokenization"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1370,"status":"ok","timestamp":1655570876647,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"J-fs0RpU0BAU"},"outputs":[],"source":["# declare the checkpoint\n","checkpoint = \"bert-base-uncased\"\n","\n","# call the tokenizer for training\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":85,"status":"ok","timestamp":1655570876656,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"wqsctMTmlB22"},"outputs":[],"source":["# create a function for tokenizing the sample_mails\n","def tokenize_function(example):\n","    return tokenizer(example[\"sample_mails\"], truncation=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["fa5f86eee50443969a0cd33309bd7127","faed0052fe0c461095f078464b9dc55c","c72399c3c7ab4781b423a60ba393b5e3","4a4884cabad94a83b0fac2c12b0574e5","df6ea8d5f4764b738c8539fdbf5f47cb","f1b50327eed54763b244185ab211cacf","00d76b58b434493abaea93735bd876d8","19bf2c0fa8c347ec84635386dba59ab5","a39c3c5ee7d24900a6c2fe359c4261d2","3c095e7707b04738952a5b4483b496b5","24c73ce427214973bde836688b2700c7"]},"executionInfo":{"elapsed":89,"status":"ok","timestamp":1655570876666,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"agGQC2dnPxNU","outputId":"d9631022-a6bd-48c6-b8df-d102b8a2c843"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa5f86eee50443969a0cd33309bd7127","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['sample_mails', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 11\n","})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# tokenize the dataset with the map function\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","tokenized_datasets"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":78,"status":"ok","timestamp":1655570876671,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"KBRzYe8fnE6h"},"outputs":[],"source":["# apply dynamic padding -- pad all the sample_mails to the length of the longest element when we batch elements together\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"NqjYk8U2nx1L"},"source":["To test this new toy, we'll slice our dataset that we would like to batch together. Here, we remove the columns idx and sample_mails as they wonâ€™t be needed and contain strings (and we canâ€™t create tensors with strings) and have a look at the lengths of each entry in the batch:"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75,"status":"ok","timestamp":1655570876672,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"80WVTJEynF6D","outputId":"0eab2d28-f044-45d2-a81a-46e3ea3ea189"},"outputs":[{"data":{"text/plain":["[7, 7, 8, 7, 7, 7, 9, 9, 9, 9, 15]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["samples = tokenized_datasets[:]\n","samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sample_mails\"]}\n","[len(x) for x in samples[\"input_ids\"]]"]},{"cell_type":"markdown","metadata":{"id":"nOXm9aNApFMv"},"source":["No surprise, we get samples of varying length, from 7 to 15. Dynamic padding means the samples in this batch should all be padded to a length of 15, the maximum length inside the batch. Without dynamic padding, all of the samples would have to be padded to the maximum length in the whole dataset, or the maximum length the model can accept. Letâ€™s double-check that our data_collator is dynamically padding the batch properly:"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61,"status":"ok","timestamp":1655570876677,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"y0UZkLubom6z","outputId":"2bcf63ae-25c8-4089-8cf0-37d695abe045"},"outputs":[{"data":{"text/plain":["{'attention_mask': torch.Size([11, 15]),\n"," 'input_ids': torch.Size([11, 15]),\n"," 'labels': torch.Size([11]),\n"," 'token_type_ids': torch.Size([11, 15])}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["batch = data_collator(samples)\n","{k: v.shape for k, v in batch.items()}"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1655570876678,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"MC4YYdKlVHVy","outputId":"21097335-efa3-4a10-adbb-81d94a7e8977"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# check if we're using a fast tokenizer\n","tokenizer.is_fast"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1655570876680,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"_lf3AFOQPyC_","outputId":"7fd91539-1f64-4510-9ffa-5b22a67c19e2"},"outputs":[{"data":{"text/plain":["['[CLS]',\n"," 'will',\n"," 'you',\n"," 'help',\n"," 'my',\n"," 'friends',\n"," 'if',\n"," 'i',\n"," 'share',\n"," 'your',\n"," 'email',\n"," 'with',\n"," 'them',\n"," '?',\n"," '[SEP]']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# we can convert the tokenized dataset back to text as follows\n","tokenizer.convert_ids_to_tokens(tokenized_datasets['input_ids'][-1])"]},{"cell_type":"markdown","metadata":{"id":"Bq1iZSRTZjRC"},"source":["### Training\n","\n","The first step before we can define our Trainer is to define a TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and evaluation. The only argument you have to provide is a directory where the trained model will be saved, in our case we want to also modify the number of epochs for training,  the checkpoints along the way are also saved in this directory. For all the rest, you can leave the defaults, which should work pretty well for a basic fine-tuning."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":453,"status":"ok","timestamp":1655570877090,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"FK6WKUMWt5gX"},"outputs":[],"source":["# define a metric to monitor during training\n","metric = load_metric(\"accuracy\")\n","\n","# create a function that helps compute the specified metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1655570877091,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"cqIKniIhUtgk"},"outputs":[],"source":["# define the training arguments\n","training_args = TrainingArguments('training_args',\n","                                  num_train_epochs=20)"]},{"cell_type":"markdown","metadata":{"id":"tQgo27OMac5X"},"source":["The second step is to define our model. We will use the AutoModelForSequenceClassification class, with two labels:"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3789,"status":"ok","timestamp":1655570880876,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"k2Qv5h4CacDc","outputId":"548e794a-b9ae-4b7a-b23b-cf6de50c7080"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"]},{"cell_type":"markdown","metadata":{"id":"pwPBV42gbgh2"},"source":["You will notice that you get a warning after instantiating this pretrained model. This is because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now."]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":6773,"status":"ok","timestamp":1655570887603,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"L9o69w-IbADb"},"outputs":[],"source":["# define trainer object\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"markdown","metadata":{"id":"1rMR-jXpdMXu"},"source":["To fine-tune the model on our dataset, we just have to call the train() method of our Trainer:"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":3466,"status":"ok","timestamp":1655570890961,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"_T110yLucf_o","outputId":"45866c2d-396b-4659-d9f7-61bce14d2223"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sample_mails. If sample_mails are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 11\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 40\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [40/40 00:03, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=40, training_loss=0.1826045036315918, metrics={'train_runtime': 3.2339, 'train_samples_per_second': 68.029, 'train_steps_per_second': 12.369, 'total_flos': 1399833036720.0, 'train_loss': 0.1826045036315918, 'epoch': 20.0})"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1802,"status":"ok","timestamp":1655570892698,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"vZjIBUq7fUUQ","outputId":"d8e99315-5a81-4daf-9d11-324363ef2ce1"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to custom_model\n","Configuration saved in custom_model/config.json\n","Model weights saved in custom_model/pytorch_model.bin\n","tokenizer config file saved in custom_model/tokenizer_config.json\n","Special tokens file saved in custom_model/special_tokens_map.json\n"]}],"source":["# save the trained model together with the tokenizer in a directory\n","trainer.save_model('custom_model')"]},{"cell_type":"markdown","metadata":{"id":"cWaWym99zcUg"},"source":["### Evaluation\n","\n","For this task, we will evaluate the model on the training set, given that the dataset is extremely small and could not be split into train-test sets"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1655570892717,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"Nkl5dLmwgYST","outputId":"9bbe2b92-cd08-4298-950c-be4b768618ce"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sample_mails. If sample_mails are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 11\n","  Batch size = 8\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2/2 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(11, 2) (11,) \n","\n","PredictionOutput(predictions=array([[-2.8567455,  2.6125207],\n","       [-2.8680387,  2.5676455],\n","       [ 2.3883843, -2.2533398],\n","       [-2.8665829,  2.6149411],\n","       [-2.7801325,  2.618008 ],\n","       [ 2.4355724, -2.1244042],\n","       [ 2.404393 , -2.2528536],\n","       [-2.8637493,  2.6661575],\n","       [-2.777838 ,  2.69716  ],\n","       [ 2.2913795, -2.1420698],\n","       [-2.8798716,  2.544542 ]], dtype=float32), label_ids=array([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.006455942988395691, 'test_accuracy': 1.0, 'test_runtime': 0.0593, 'test_samples_per_second': 185.544, 'test_steps_per_second': 33.735})\n"]}],"source":["predictions = trainer.predict(tokenized_datasets)\n","print(predictions.predictions.shape, predictions.label_ids.shape, '\\n')\n","print(predictions)"]},{"cell_type":"markdown","metadata":{"id":"hS1xBv2f3oM-"},"source":["The output of the `predict()` method is another named tuple with three fields: predictions, `label_ids`, and `metrics`. The metrics field now contains the loss on the dataset passed, some time metrics (how long it took to predict, in total and on average), and the accuracy of training\n","\n","As we can see, predictions is a two-dimensional array with shape 11 x 2 (11 being the number of elements in the dataset we used). Those are the logits for each element of the dataset we passed to `predict()`. To transform them into predictions that we can compare to our labels, we need to take the index with the maximum value on the second axis:"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1655570892720,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"tWrsESYHqtgm"},"outputs":[],"source":["preds = np.argmax(predictions.predictions, axis=-1)"]},{"cell_type":"markdown","metadata":{"id":"NxjkyUq-6VVA"},"source":["We can now compare those preds to the labels. To build our `compute_metric()` function, we will rely on the metrics from the ðŸ¤— Datasets library. We can load the metrics associated with the MRPC dataset as easily as we loaded the dataset, this time with the `load_metric()` function. The object returned has a `compute()` method we can use to do the metric calculation. Wrapping everything together, we get our `compute_metrics_mrpc()` function:"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655570893158,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"xpiiHNIM882M"},"outputs":[],"source":["def compute_metrics_mrpc(eval_preds):\n","    metric = load_metric(\"glue\", \"mrpc\")\n","    logits, labels = eval_preds.predictions, eval_preds.label_ids\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1655570893515,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"gGs9IY4m-G-I","outputId":"19c64b2f-8a60-4917-92e2-061864b3abcc"},"outputs":[{"data":{"text/plain":["{'accuracy': 1.0, 'f1': 1.0}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["compute_metrics_mrpc(predictions)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1655570893516,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"9Sn6-O-p-dDr","outputId":"b28619c3-deb4-463e-96f3-ff62f9abcbf5"},"outputs":[{"data":{"text/plain":["array([[-2.8567455,  2.6125207],\n","       [-2.8680387,  2.5676455],\n","       [ 2.3883843, -2.2533398],\n","       [-2.8665829,  2.6149411],\n","       [-2.7801325,  2.618008 ],\n","       [ 2.4355724, -2.1244042],\n","       [ 2.404393 , -2.2528536],\n","       [-2.8637493,  2.6661575],\n","       [-2.777838 ,  2.69716  ],\n","       [ 2.2913795, -2.1420698],\n","       [-2.8798716,  2.544542 ]], dtype=float32)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["predictions.predictions"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1655570893518,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"KQH9c_mv-NeE","outputId":"c2ca3852-e68f-49cd-dee2-6571731daad8"},"outputs":[{"data":{"text/plain":["array([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["predictions.label_ids"]},{"cell_type":"markdown","metadata":{"id":"9FRTXK4zu14Q"},"source":["From the above, we see that the model has a perfect prediction on the data it was trained on. This is highly flawed and can be ascribed to overfitting, but since we have no test set to evaluate on given the size of the sample data, we can assume that for the model to overfit at 20 epochs, it actually did well in learning the training dataset.\n","\n","### Inference"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2223,"status":"ok","timestamp":1655573150063,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"LZI4lSsd_6Up","outputId":"00bd1179-48de-4dbb-c68d-7acfaae6fda8"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file /content/drive/MyDrive/Code_challenge/custom_model/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Code_challenge/custom_model/\",\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.20.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file /content/drive/MyDrive/Code_challenge/custom_model/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Code_challenge/custom_model/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"]}],"source":["# get the directory where the model was saved to\n","inf_model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/Code_challenge/custom_model/')"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1655573338250,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"IB80F5BT2W5r","outputId":"f4e87cc7-c38b-40d7-d376-6899aee91d52"},"outputs":[{"name":"stderr","output_type":"stream","text":["Didn't find file /content/drive/MyDrive/Code_challenge/custom_model/added_tokens.json. We won't load it.\n","loading file /content/drive/MyDrive/Code_challenge/custom_model/vocab.txt\n","loading file /content/drive/MyDrive/Code_challenge/custom_model/tokenizer.json\n","loading file None\n","loading file /content/drive/MyDrive/Code_challenge/custom_model/special_tokens_map.json\n","loading file /content/drive/MyDrive/Code_challenge/custom_model/tokenizer_config.json\n"]}],"source":["# load the tokenizer by pointing to the same directory as the pretrained model\n","inf_tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/Code_challenge/custom_model/')"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1655575117312,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"2hCuCbqM23CI"},"outputs":[],"source":["# generate sequence for inference\n","sequences = ['I want to know if I should send your email', 'I sent your email a long time ago']"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":809,"status":"ok","timestamp":1655574094394,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"vLVXPplE3xxl"},"outputs":[],"source":["# create a pipeline for inference\n","from transformers import pipeline\n","classifier = pipeline(task='text-classification', model=inf_model, tokenizer=inf_tokenizer)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1655575120730,"user":{"displayName":"Ifeanyi Akawi","userId":"10822053801368667109"},"user_tz":-60},"id":"UgGbs7b65FDU","outputId":"d05c6a45-a20a-4995-edca-62da3f48d494"},"outputs":[{"name":"stderr","output_type":"stream","text":["Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"]},{"data":{"text/plain":["[{'label': 'LABEL_1', 'score': 0.6547055840492249},\n"," {'label': 'LABEL_0', 'score': 0.9795986413955688}]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["classifier(sequences)"]},{"cell_type":"markdown","metadata":{"id":"EJxapWpg7hlG"},"source":["From the above output, we can confidently say the model is performing well on inference"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMu8uMKYqRgHJuCZ6XQuSiq","collapsed_sections":[],"mount_file_id":"1pZMgEIulV3c4SiuhbryXmdfF9-YkUv86","name":"train_model.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00d76b58b434493abaea93735bd876d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d8302ca67134193a10ade69c44041bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89e96f9fcfed418895ef4887072b134d","IPY_MODEL_c6b02c2d616f41af9ded54c7916709ee","IPY_MODEL_b88ce659f6f4451eb43bf7bd6610f0d6"],"layout":"IPY_MODEL_30b853bfac2d4eafafa5208e914aa40e"}},"10ef2c11a1754e708834372100e6eb5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1cf39a62d064404920f5dbc2175829e","placeholder":"â€‹","style":"IPY_MODEL_d1d37f46d21e476b80319fb3143055ff","value":" 1/1 [00:00&lt;00:00, 17.49ba/s]"}},"19bf2c0fa8c347ec84635386dba59ab5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24c73ce427214973bde836688b2700c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27549b8720c741199e42b55049ac1c1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_823582762af34fa3b85ab758fc06d8a3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df7418fee5f34b0584500f63aaa480eb","value":1}},"30b853bfac2d4eafafa5208e914aa40e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36c4eb53fb1f40f9bd232c59979d52db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c095e7707b04738952a5b4483b496b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"459c48905efe477cb25c5eb8dc3c0571":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe8e0db9a7ce4810974b58c0f7fb9ff4","placeholder":"â€‹","style":"IPY_MODEL_840f26b2aa4640b4919625d9504df3f6","value":"Casting the dataset: 100%"}},"4a4884cabad94a83b0fac2c12b0574e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c095e7707b04738952a5b4483b496b5","placeholder":"â€‹","style":"IPY_MODEL_24c73ce427214973bde836688b2700c7","value":" 1/1 [00:00&lt;00:00, 11.43ba/s]"}},"5fe39bf5c8d446dc8dc9aa86429b7423":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7202ebce10d943f5885631fc36418058":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"823582762af34fa3b85ab758fc06d8a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840f26b2aa4640b4919625d9504df3f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89e96f9fcfed418895ef4887072b134d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fe39bf5c8d446dc8dc9aa86429b7423","placeholder":"â€‹","style":"IPY_MODEL_bf060a5ee51b458aa6517a3bf503e59b","value":"Casting to class labels: 100%"}},"a2505a274ff243589f05bf088c1e0992":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a39c3c5ee7d24900a6c2fe359c4261d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7032e7ea083403d9abf038b48c328e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b88ce659f6f4451eb43bf7bd6610f0d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9214a7b86334b92b3df3f3389cf154e","placeholder":"â€‹","style":"IPY_MODEL_7202ebce10d943f5885631fc36418058","value":" 1/1 [00:00&lt;00:00, 24.78ba/s]"}},"bf060a5ee51b458aa6517a3bf503e59b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1cf39a62d064404920f5dbc2175829e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b02c2d616f41af9ded54c7916709ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2505a274ff243589f05bf088c1e0992","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36c4eb53fb1f40f9bd232c59979d52db","value":1}},"c72399c3c7ab4781b423a60ba393b5e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19bf2c0fa8c347ec84635386dba59ab5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a39c3c5ee7d24900a6c2fe359c4261d2","value":1}},"d1d37f46d21e476b80319fb3143055ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df6ea8d5f4764b738c8539fdbf5f47cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df7418fee5f34b0584500f63aaa480eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1b50327eed54763b244185ab211cacf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9214a7b86334b92b3df3f3389cf154e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f954762c305c4be9ae3fd2682e7efe53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_459c48905efe477cb25c5eb8dc3c0571","IPY_MODEL_27549b8720c741199e42b55049ac1c1f","IPY_MODEL_10ef2c11a1754e708834372100e6eb5b"],"layout":"IPY_MODEL_b7032e7ea083403d9abf038b48c328e5"}},"fa5f86eee50443969a0cd33309bd7127":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_faed0052fe0c461095f078464b9dc55c","IPY_MODEL_c72399c3c7ab4781b423a60ba393b5e3","IPY_MODEL_4a4884cabad94a83b0fac2c12b0574e5"],"layout":"IPY_MODEL_df6ea8d5f4764b738c8539fdbf5f47cb"}},"faed0052fe0c461095f078464b9dc55c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1b50327eed54763b244185ab211cacf","placeholder":"â€‹","style":"IPY_MODEL_00d76b58b434493abaea93735bd876d8","value":"100%"}},"fe8e0db9a7ce4810974b58c0f7fb9ff4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
